{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRIPLET LOSS CNN IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Model import triplet_model, embed_model\n",
    "from utils import genre_count_dataset, img_from_ID, images_from_ids\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data.csv\n",
    "Contains\n",
    "* Id\n",
    "* Genre\n",
    "* Song Name\n",
    "* Spectrogram(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET SHAPE (3208, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Spectrogram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Classical</td>\n",
       "      <td>Beethoven-Symphony 9</td>\n",
       "      <td>Spectrograms/Classical/Beethoven-Symphony 9/Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Classical</td>\n",
       "      <td>Beethoven-Symphony 9</td>\n",
       "      <td>Spectrograms/Classical/Beethoven-Symphony 9/Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Classical</td>\n",
       "      <td>Beethoven-Symphony 9</td>\n",
       "      <td>Spectrograms/Classical/Beethoven-Symphony 9/Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Classical</td>\n",
       "      <td>Beethoven-Symphony 9</td>\n",
       "      <td>Spectrograms/Classical/Beethoven-Symphony 9/Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Classical</td>\n",
       "      <td>Beethoven-Symphony 9</td>\n",
       "      <td>Spectrograms/Classical/Beethoven-Symphony 9/Be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id      Genre             Song Name  \\\n",
       "0   1  Classical  Beethoven-Symphony 9   \n",
       "1   2  Classical  Beethoven-Symphony 9   \n",
       "2   3  Classical  Beethoven-Symphony 9   \n",
       "3   4  Classical  Beethoven-Symphony 9   \n",
       "4   5  Classical  Beethoven-Symphony 9   \n",
       "\n",
       "                                         Spectrogram  \n",
       "0  Spectrograms/Classical/Beethoven-Symphony 9/Be...  \n",
       "1  Spectrograms/Classical/Beethoven-Symphony 9/Be...  \n",
       "2  Spectrograms/Classical/Beethoven-Symphony 9/Be...  \n",
       "3  Spectrograms/Classical/Beethoven-Symphony 9/Be...  \n",
       "4  Spectrograms/Classical/Beethoven-Symphony 9/Be...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"DATASET SHAPE\",data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET GENRE COMPOSITION\n",
      "\n",
      "Classical 595\n",
      "Hip-Hop 573\n",
      "Metal 643\n",
      "Rock 469\n",
      "Pop 462\n",
      "Country 466\n"
     ]
    }
   ],
   "source": [
    "print(\"DATASET GENRE COMPOSITION\\n\")\n",
    "cl, h ,m ,r ,p ,co = genre_count_dataset(data, data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CALLING EMBEDDING MODEL\n",
    "* embed_model gives 128 embeddings corresponding to a spectrogram image (128,1402,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "submodel = embed_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 1402, 1)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 134, 1408, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 701, 64)       3200      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 701, 64)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 66, 703, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 351, 64)       0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 32, 351, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 32, 351, 64)       4160      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 351, 64)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 34, 353, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 32, 351, 192)      110784    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 351, 192)      0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 32, 351, 192)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 34, 353, 192)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 176, 192)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 176, 96)       18528     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 176, 96)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 18, 178, 96)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 88, 96)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 88, 96)         9312      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 88, 96)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 10, 90, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 44, 96)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 42, 128)        110720    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2, 42, 128)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 4, 44, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 21, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 21, 16)         2064      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1, 21, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 336)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               172544    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "l2_norm (Lambda)             (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 496,976\n",
      "Trainable params: 496,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "submodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CALL TRIPLET MODEL\n",
    "* Gets you triplet model\n",
    "* implements triplet loss\n",
    "* metric accuracy for custom accuracy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spari\\Projects\\DM_Pro\\DataMonk--Music-Similarity-master\\Triplet Loss Model\\Model.py:143: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name='loss', output_shape=(1, ))\n",
      "C:\\Users\\spari\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\Users\\spari\\Projects\\DM_Pro\\DataMonk--Music-Similarity-master\\Triplet Loss Model\\Model.py:145: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"lo...)`\n",
      "  model = Model(input=[anchor_input, positive_input, negative_input], output=loss)\n"
     ]
    }
   ],
   "source": [
    "triplet_model = triplet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 128, 1402, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 128, 1402, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 128, 1402, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 128)          496976      anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "loss (Merge)                    (None, 1)            0           model_2[1][0]                    \n",
      "                                                                 model_2[2][0]                    \n",
      "                                                                 model_2[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 496,976\n",
      "Trainable params: 496,976\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATING TRIPLETS\n",
    "Concept:\n",
    "* Pick n (32) random anchor points (ids from database)\n",
    "* Make a remaining list containing ids not included by anchors\n",
    "* For each anchor find most optimal semi-hard positives and negatives.\n",
    "\n",
    "\n",
    "Concept for chosing triplets:\n",
    "* Choose a positive from same genre but farthest in distance (embedding distance np.linalg.norm) to the anchor.\n",
    "* Choose a negative from differest genre but closest in distance to the anchor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET IMAGES FROM ID (SPECTROGRAM PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added to dataframe\n"
     ]
    }
   ],
   "source": [
    "data = images_from_ids(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 1402, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Images[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_img_from_ID(data, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_batch = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets():  \n",
    "            import time\n",
    "            trip_ids = []\n",
    "            triplets  = []\n",
    "            \n",
    "            # id's \n",
    "            anchors = random.sample(list(range(1,data.shape[0]+1)), anchor_batch)\n",
    "            remaining = [i for i in range(1, data.shape[0]+1) if i not in anchors]\n",
    "            start_time = time.time()\n",
    "            \n",
    "            for a in tqdm(anchors): \n",
    "                pos_embeds = []\n",
    "                neg_embeds = []\n",
    "\n",
    "                pos_dict = {}\n",
    "                neg_dict = {}\n",
    "\n",
    "                \n",
    "                # got embeddings, genre of an id in anchor\n",
    "                a_img = img_from_ID(data, a)\n",
    "                a_embed = submodel.predict_on_batch(a_img)                \n",
    "                a_genre = data.loc[a-1]['Genre'] \n",
    "                \n",
    "                \n",
    "                for rem in remaining:\n",
    "                    # iterating over remaining and checking for its genre, embed\n",
    "                    rem_img = img_from_ID(data,rem)\n",
    "                    rem_embed = submodel.predict_on_batch(rem_img)\n",
    "                    rem_genre = data.loc[rem-1]['Genre']\n",
    "\n",
    "\n",
    "                    # id's genre embeddings\n",
    "                    if (a_genre == rem_genre):\n",
    "                                  \n",
    "                        #dictionary of ids : distance\n",
    "                        pos_dict[rem] = np.linalg.norm(rem_embed - a_embed)\n",
    "                        \n",
    "\n",
    "                    else:\n",
    "                        neg_dict[rem] = np.linalg.norm(rem_embed - a_embed)\n",
    "            \n",
    "#             return neg_ids, pos_ids\n",
    "\n",
    "\n",
    "                # indices of min distance neg and max distance pos\n",
    "                pos_index = max(pos_dict.items(), key=operator.itemgetter(1))[0]\n",
    "                neg_index = min(neg_dict.items(), key=operator.itemgetter(1))[0]\n",
    "            \n",
    "#                 print(pos_index)\n",
    "\n",
    "                # add images corresponding to indices \n",
    "                anchor_img = img_from_ID(data, a)\n",
    "                positive_img =img_from_ID(data, pos_index)\n",
    "                negative_img = img_from_ID(data, neg_index)\n",
    "                \n",
    "                trip_ids.append([a, pos_index, neg_index])\n",
    "                triplets.append([anchor_img, positive_img, negative_img])\n",
    "           \n",
    "            trip_ids = np.array(trip_ids)\n",
    "            triplets = np.array(triplets)\n",
    "            triplets = triplets.reshape(anchor_batch,3, 128, 1402,1)\n",
    "            \n",
    "            print(\"Execution Time: \", time.time()-start_time) \n",
    "            return trip_ids, triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tripvec = np.vectorize(generate_triplets, otypes=[np.ndarray])\n",
    "# treip_ids, trip = tripvec()\n",
    "\n",
    "# # n,p = generate_triplets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip = np.array(trip)\n",
    "# treip_ids = np.array(treip_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treip_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip = trip.reshape(anchor_batch,3, 128, 1402,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit and evaluate\n",
    "* Model.fit - fits the triplets into the model using accurcay (custom metric) and triplet loss\n",
    "\n",
    "* Model.evaluate - evaluates on the metrics the model was compiled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "split = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/32 [00:00<?, ?it/s]\n",
      "  3%|██▌                                                                                | 1/32 [00:21<11:15, 21.80s/it]\n",
      "  6%|█████▏                                                                             | 2/32 [00:37<09:16, 18.55s/it]\n",
      "  9%|███████▊                                                                           | 3/32 [00:52<08:23, 17.34s/it]\n",
      " 12%|██████████▍                                                                        | 4/32 [01:06<07:48, 16.73s/it]\n",
      " 16%|████████████▉                                                                      | 5/32 [01:21<07:21, 16.36s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    print('Epoch %s' % epoch)\n",
    "    \n",
    "    \n",
    "    tripvec = np.vectorize(generate_triplets, otypes=[np.ndarray])\n",
    "    trip_ids, trip = tripvec()\n",
    "    \n",
    "    anchors = trip[:,0]\n",
    "    positives = trip[:,1]\n",
    "    negatives = trip[:,2]\n",
    "    \n",
    "#     print(trip.shape)\n",
    "    \n",
    "    triplet_model.fit([anchors, positives, negatives], y = np.zeros(32), batch_size= 32, verbose = 1)\n",
    "    \n",
    "    if(epoch% split==0):\n",
    "        triplet_model.evaluate([anchors, positives, negatives], y = np.zeros(32), verbose=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN TILL HERE FIRST!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLUSTERING USING KNN  -- SUPERVISED (On Genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPARATION\n",
    "* Copy data into new dataframe\n",
    "* Get me embeddings of each song from embed_model (Embedding column)\n",
    "* Save to csv (embed_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_data = data.copy(deep= True)\n",
    "embeddings = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    curr_id = data.Id [i] \n",
    "    test_point = img_from_ID(data,curr_id)\n",
    "    curr_embedding = submodel.predict_on_batch(test_point)\n",
    "    curr_embedding = np.ndarray.tolist(curr_embedding)\n",
    "    embeddings.append(np.array(curr_embedding[0]))\n",
    "#     embeddings =  np.array(embeddings)\n",
    "    \n",
    "    \n",
    "embed_data['Embeddings'] =embeddings\n",
    "embed_data.Embeddings[0].shape\n",
    "# np.savetxt('test.csv', embed_data) \n",
    "embed_data.to_csv('embed_dataa.csv', na_rep = None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_data.Embeddings[0].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USER INPUT CASE (Imagining its not in database rn)\n",
    "CONTEXT-\n",
    "User inputs a value or new song\n",
    "\n",
    "FOR NOW-\n",
    "Picking random point from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_id = data.Id [0] \n",
    "test_point = img_from_ID(data,curr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_point.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get me embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = submodel.predict_on_batch(test_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING KNN APPROACH: SHOW ME WHAT YOU'VE GOT KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edata = pd.read_csv(\"embed_dataa.csv\")\n",
    "X = embed_data.drop(['Id','Genre',' Spectrogram','Song Name'],axis=1)\n",
    "y = embed_data['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Embeddings[9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Embeddings[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values.T.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR - Cant convert string to float_32\n",
    "* Embeddings (python list) saving as string in csv\n",
    "* Cant fit string in KNN!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.Embeddings = X.Embeddings.convert_object(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X[0], y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(embed_data.shape[0]):\n",
    "#     print(embed_data.Embeddings[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### X_train.shape\n",
    "knn.fit(np.array(X_train), np.array(y_train))\n",
    "pred = knn.predict(np.array(X_test))\n",
    "print (accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTPUT\n",
    "* Gets me class of genre for test data point (pred)\n",
    "* Now I know the accuracy too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN NEXT STEP \n",
    "#### AIM - Suggest me top k (5) similar songs please!\n",
    "\n",
    "* I've predicted the class of genre my input song belongs to. Now I need to pick top 5 Song Name from this Genre with lease distant spectrogram embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new random point \n",
    "## call predict on it\n",
    "pred = knn.predict([X_test[0]])\n",
    "## class of genre\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggestions of top 5 songs\n",
    "curr_embed = (X_test[0])\n",
    "predicted_Genre = pred\n",
    "dist = []\n",
    "dict = {}\n",
    "for i in range(edata.shape[0]):\n",
    "    if edata.Genre[i] == predicted_Genre:\n",
    "        dist = np.linalg.norm(np.array(edata.Embeddings[i]),curr_embed)\n",
    "#         dict.append([i])\n",
    "        dist = np.sort(dist, axis = None)\n",
    "        \n",
    "print(dist[5:])\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLUSTERING USING K Means  -- UNSUPERVISED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6 , random_state=32).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.predict(X_test)\n",
    "# kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "for i in range(X.shape[0]):\n",
    "    if kmeans.labels_[i] == 0:\n",
    "        c1 = pl.scatter(X,y,c='r',  marker='+')\n",
    "    \n",
    "# elif kmeans.labels_[i] == 0:\n",
    "#     c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='g',\n",
    "#    marker='o')\n",
    "# elif kmeans.labels_[i] == 2:\n",
    "#     c3 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='b',\n",
    "#     marker='*')\n",
    "# pl.legend([c1, c2, c3],['Cluster 1', 'Cluster 0',\n",
    "#     'Cluster 2'])\n",
    "\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
